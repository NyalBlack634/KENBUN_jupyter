{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"jawiki.all_vectors.200d-002.txt\"\n",
    "model = KeyedVectors.load_word2vec_format(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word2vec_model.pickle', mode='wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word2vec_model.pickle', mode='rb') as f:\n",
    "    test_pickle_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mojimoji\n",
    "import MeCab as mc\n",
    "\n",
    "m = mc.Tagger(\"-Ochasen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_tokenizer(text: str):\n",
    "    \"\"\"\n",
    "    テキストを分かち書きするメソッド\n",
    "    :param text: 分割したいテキスト\n",
    "    :return: 分割後のテキスト\n",
    "    \"\"\"\n",
    "\n",
    "    node = m.parseToNode(text)\n",
    "    word_list = list()\n",
    "    while node:\n",
    "        if node.surface != \"\":\n",
    "            res = node.feature.split(\",\")\n",
    "            word_type = res[0]\n",
    "            if word_type in ['名詞', \"動詞\", \"形容詞\", \"副詞\"]:  # 名詞, 動詞, 形容詞, 副詞のみを抽出\n",
    "                basic_word = res[6]\n",
    "                if basic_word != \"*\":\n",
    "                    word_list.append(basic_word)\n",
    "                else:\n",
    "                    word_list.append('[UNK]')  # 未知語の場合は[UNK]トークンに置き換え\n",
    "        node = node.next\n",
    "        if node is None:\n",
    "            break\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_word(text: str):\n",
    "    \"\"\"\n",
    "    元word_analysis()\n",
    "    ベクトル化を行うメソッド\n",
    "    :param text: ベクトル化するテキスト\n",
    "    :return: ベクトル化したテキスト(array型)\n",
    "    \"\"\"\n",
    "\n",
    "    text = clean_text(text)\n",
    "\n",
    "    V = list()  # 文章のベクトル(200次元)を格納\n",
    "\n",
    "    # 文章の対して, 文章中の単語のベクトルの平均を求める処理を行う\n",
    "    word_list = mecab_tokenizer(text)\n",
    "    v = np.array([0.0] * 200)\n",
    "    word_num = 0\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            v += np.array(model[word])\n",
    "        except KeyError as error:\n",
    "            continue\n",
    "        except ValueError as verror:\n",
    "            continue\n",
    "        word_num += 1\n",
    "\n",
    "    try:\n",
    "        v = v / word_num\n",
    "    except ZeroDivisionError as e:\n",
    "        print(f'ZeroDivisionError: {e}')\n",
    "\n",
    "    return v\n",
    "\n",
    "def cos_sim(v1, v2):\n",
    "    \"\"\"\n",
    "    cos類似度を計算\n",
    "    :param v1: word2vecによりベクトル化したテキスト1(ndarray型)\n",
    "    :param v2: word2vecによりベクトル化したテキスト2(ndarray型)\n",
    "    :return: 二つのテキストのcos類似度\n",
    "    \"\"\"\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str):\n",
    "    \"\"\"\n",
    "    テキストの正規化\n",
    "    :param text: 正規化するテキスト\n",
    "    :return: 正規化後のテキスト\n",
    "    \"\"\"\n",
    "    text = mojimoji.han_to_zen(text, digit=False, ascii=False)  # 半角文字を全角文字に統一(数字, 英語以外)\n",
    "    text = mojimoji.zen_to_han(text, kana=False)  # 全角文字を半角文字に統一(かな以外)\n",
    "    text = text.lower()  # 小文字に統一\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word = '縣体協の學 童相撲人會'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_word_pickle(text: str):\n",
    "    \"\"\"\n",
    "    元word_analysis()\n",
    "    ベクトル化を行うメソッド\n",
    "    :param text: ベクトル化するテキスト\n",
    "    :return: ベクトル化したテキスト(array型)\n",
    "    \"\"\"\n",
    "\n",
    "    text = clean_text(text)\n",
    "\n",
    "    V = list()  # 文章のベクトル(200次元)を格納\n",
    "\n",
    "    # 文章の対して, 文章中の単語のベクトルの平均を求める処理を行う\n",
    "    word_list = mecab_tokenizer(text)\n",
    "    v = np.array([0.0] * 200)\n",
    "    word_num = 0\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            v += np.array(test_pickle_model[word])\n",
    "        except KeyError as error:\n",
    "            continue\n",
    "        except ValueError as verror:\n",
    "            continue\n",
    "        word_num += 1\n",
    "\n",
    "    try:\n",
    "        v = v / word_num\n",
    "    except ZeroDivisionError as e:\n",
    "        print(f'ZeroDivisionError: {e}')\n",
    "\n",
    "    return v\n",
    "\n",
    "def cos_sim(v1, v2):\n",
    "    \"\"\"\n",
    "    cos類似度を計算\n",
    "    :param v1: word2vecによりベクトル化したテキスト1(ndarray型)\n",
    "    :param v2: word2vecによりベクトル化したテキスト2(ndarray型)\n",
    "    :return: 二つのテキストのcos類似度\n",
    "    \"\"\"\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_vector = vectorize_word(test_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05823259, -0.16913912, -0.05173661, -0.17274819, -0.0403929 ,\n",
       "       -0.03585067,  0.19111562,  0.13368553, -0.25446417,  0.08546442,\n",
       "       -0.09687355, -0.33496718, -0.11772048,  0.02910109,  0.14799757,\n",
       "       -0.20030577,  0.13155583, -0.11711848, -0.07376874, -0.10243418,\n",
       "        0.11118599,  0.01274949, -0.59391406,  0.02399342,  0.09026742,\n",
       "       -0.03922956, -0.11410013,  0.14471516, -0.10006444, -0.11508192,\n",
       "        0.11593011, -0.13577288,  0.14044928, -0.08384098,  0.08344796,\n",
       "       -0.04024466, -0.25533674,  0.29996674, -0.37464159, -0.15103976,\n",
       "       -0.10001664,  0.32393306, -0.00280211,  0.05887438, -0.07633487,\n",
       "       -0.01925723,  0.43012448, -0.37823561, -0.08142076,  0.08572617,\n",
       "       -0.23463002, -0.01279685,  0.07153545,  0.04136499, -0.11128016,\n",
       "       -0.19464023,  0.06922324, -0.04747667, -0.04059302, -0.1252287 ,\n",
       "        0.12948431, -0.30929148,  0.0494603 , -0.11413988,  0.22758553,\n",
       "       -0.16626524, -0.01561721, -0.26964435,  0.28762528,  0.21182576,\n",
       "        0.20410769,  0.02424129, -0.0347302 ,  0.42879457, -0.08979674,\n",
       "       -0.09879188,  0.20294782, -0.07982053,  0.14729554, -0.1093588 ,\n",
       "        0.18921226,  0.06539426, -0.03272253, -0.03847347,  0.06109507,\n",
       "       -0.13253331,  0.06846083,  0.24679644, -0.17710882,  0.20422819,\n",
       "        0.42864148,  0.07274099,  0.09159136,  0.36687706,  0.00769122,\n",
       "       -0.01109102, -0.04673125, -0.24667358,  0.06982877, -0.07365767,\n",
       "        0.08048332, -0.27621791,  0.31063626,  0.35355505, -0.2069296 ,\n",
       "       -0.08626413,  0.02691507, -0.20312423,  0.04574584, -0.13650482,\n",
       "       -0.20449332, -0.19609995,  0.08330919,  0.19246211, -0.03564815,\n",
       "        0.0368583 , -0.18270517,  0.00757294,  0.03413328,  0.00951345,\n",
       "        0.08041973,  0.01986164, -0.0905972 , -0.277846  , -0.10211586,\n",
       "        0.10054605,  0.3007117 ,  0.00842173,  0.22080689, -0.17653039,\n",
       "       -0.48225436, -0.12870763, -0.02157139, -0.03623558, -0.33352976,\n",
       "        0.14462521,  0.19174983, -0.04008398,  0.03125647, -0.19052231,\n",
       "        0.01200811, -0.12353391,  0.31048964,  0.28173515,  0.19457173,\n",
       "        0.30194405, -0.12611159, -0.04235432,  0.03113568,  0.12896583,\n",
       "       -0.07087881,  0.05755422, -0.17968499, -0.11648213, -0.14290977,\n",
       "        0.19443864, -0.15494075,  0.01945718,  0.09842117, -0.0334687 ,\n",
       "        0.25420105, -0.10074515,  0.10264075, -0.12588781,  0.04182064,\n",
       "        0.1053896 , -0.0845862 ,  0.04603907, -0.04488109,  0.18694883,\n",
       "        0.02455349, -0.15543371,  0.15755202, -0.19991259, -0.18852789,\n",
       "        0.25691501, -0.09542637,  0.01612303, -0.0646132 , -0.01132516,\n",
       "       -0.03371594,  0.02319092,  0.07292308,  0.23851298, -0.26158861,\n",
       "        0.23753431, -0.11917343,  0.22263238, -0.18643735,  0.12525626,\n",
       "       -0.09602162, -0.08816071, -0.12164548, -0.16740753,  0.20803114,\n",
       "        0.21548115,  0.12470078,  0.23479901,  0.26978224, -0.3322477 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_vector = vectorize_word_pickle(test_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05823259, -0.16913912, -0.05173661, -0.17274819, -0.0403929 ,\n",
       "       -0.03585067,  0.19111562,  0.13368553, -0.25446417,  0.08546442,\n",
       "       -0.09687355, -0.33496718, -0.11772048,  0.02910109,  0.14799757,\n",
       "       -0.20030577,  0.13155583, -0.11711848, -0.07376874, -0.10243418,\n",
       "        0.11118599,  0.01274949, -0.59391406,  0.02399342,  0.09026742,\n",
       "       -0.03922956, -0.11410013,  0.14471516, -0.10006444, -0.11508192,\n",
       "        0.11593011, -0.13577288,  0.14044928, -0.08384098,  0.08344796,\n",
       "       -0.04024466, -0.25533674,  0.29996674, -0.37464159, -0.15103976,\n",
       "       -0.10001664,  0.32393306, -0.00280211,  0.05887438, -0.07633487,\n",
       "       -0.01925723,  0.43012448, -0.37823561, -0.08142076,  0.08572617,\n",
       "       -0.23463002, -0.01279685,  0.07153545,  0.04136499, -0.11128016,\n",
       "       -0.19464023,  0.06922324, -0.04747667, -0.04059302, -0.1252287 ,\n",
       "        0.12948431, -0.30929148,  0.0494603 , -0.11413988,  0.22758553,\n",
       "       -0.16626524, -0.01561721, -0.26964435,  0.28762528,  0.21182576,\n",
       "        0.20410769,  0.02424129, -0.0347302 ,  0.42879457, -0.08979674,\n",
       "       -0.09879188,  0.20294782, -0.07982053,  0.14729554, -0.1093588 ,\n",
       "        0.18921226,  0.06539426, -0.03272253, -0.03847347,  0.06109507,\n",
       "       -0.13253331,  0.06846083,  0.24679644, -0.17710882,  0.20422819,\n",
       "        0.42864148,  0.07274099,  0.09159136,  0.36687706,  0.00769122,\n",
       "       -0.01109102, -0.04673125, -0.24667358,  0.06982877, -0.07365767,\n",
       "        0.08048332, -0.27621791,  0.31063626,  0.35355505, -0.2069296 ,\n",
       "       -0.08626413,  0.02691507, -0.20312423,  0.04574584, -0.13650482,\n",
       "       -0.20449332, -0.19609995,  0.08330919,  0.19246211, -0.03564815,\n",
       "        0.0368583 , -0.18270517,  0.00757294,  0.03413328,  0.00951345,\n",
       "        0.08041973,  0.01986164, -0.0905972 , -0.277846  , -0.10211586,\n",
       "        0.10054605,  0.3007117 ,  0.00842173,  0.22080689, -0.17653039,\n",
       "       -0.48225436, -0.12870763, -0.02157139, -0.03623558, -0.33352976,\n",
       "        0.14462521,  0.19174983, -0.04008398,  0.03125647, -0.19052231,\n",
       "        0.01200811, -0.12353391,  0.31048964,  0.28173515,  0.19457173,\n",
       "        0.30194405, -0.12611159, -0.04235432,  0.03113568,  0.12896583,\n",
       "       -0.07087881,  0.05755422, -0.17968499, -0.11648213, -0.14290977,\n",
       "        0.19443864, -0.15494075,  0.01945718,  0.09842117, -0.0334687 ,\n",
       "        0.25420105, -0.10074515,  0.10264075, -0.12588781,  0.04182064,\n",
       "        0.1053896 , -0.0845862 ,  0.04603907, -0.04488109,  0.18694883,\n",
       "        0.02455349, -0.15543371,  0.15755202, -0.19991259, -0.18852789,\n",
       "        0.25691501, -0.09542637,  0.01612303, -0.0646132 , -0.01132516,\n",
       "       -0.03371594,  0.02319092,  0.07292308,  0.23851298, -0.26158861,\n",
       "        0.23753431, -0.11917343,  0.22263238, -0.18643735,  0.12525626,\n",
       "       -0.09602162, -0.08816071, -0.12164548, -0.16740753,  0.20803114,\n",
       "        0.21548115,  0.12470078,  0.23479901,  0.26978224, -0.3322477 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(origin_vector, pickle_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 読み込み解決したわ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f159775bd259790cc69408ea88848223f9364821d8f03f4bf40cd893d2e21c5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
